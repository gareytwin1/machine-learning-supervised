{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "712e2535",
      "metadata": {
        "id": "712e2535"
      },
      "source": [
        "# Introduction to Machine Learning: Supervised Learning\n",
        "\n",
        "**Instructor:** Daniel Acuna, Ph.D.\n",
        "**Position:** Associate Professor of Computer Science\n",
        "**Institution:** University of Colorado Boulder\n",
        "\n",
        "---\n",
        "\n",
        "Lab 3: Classification Methods\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4775ee5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "340915b45e740163d0721e364d4e26d5",
          "grade": false,
          "grade_id": "imports",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "c4775ee5"
      },
      "outputs": [],
      "source": [
        "# ## Setup (do not edit)\n",
        "#\n",
        "# This cell imports all necessary libraries for the assignment.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc,\n",
        ")\n",
        "\n",
        "# Set a random state for reproducibility\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3901d9a",
      "metadata": {
        "id": "a3901d9a"
      },
      "source": [
        "## 1. Load and Describe the Data (10 points)\n",
        "\n",
        "The dataset for this lab is the **Wisconsin Breast Cancer dataset**. The features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The target column, `diagnosis`, indicates whether a tumor is **M** (malignant) or **B** (benign)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb2c093",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d4c5cf9730d00430b5052d2de69fbac",
          "grade": false,
          "grade_id": "w3-q1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7eb2c093"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 1\n",
        "#\n",
        "# Task: Load the dataset and display its first 5 rows.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Load the 'wisconsin_breast_cancer.csv' file into a pandas DataFrame called `df`.\n",
        "# 2. Use the `.head()` method to display the first 5 rows.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "df = pd.read_csv('wisconsin_breast_cancer.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7c4cfc",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0d98e713132b5c8b303bc22247866d23",
          "grade": true,
          "grade_id": "w3-q1-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4a7c4cfc"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 1\n",
        "assert \"df\" in locals(), \"DataFrame 'df' not found.\"\n",
        "assert df.shape[0] > 0, \"DataFrame 'df' is empty.\"\n",
        "assert \"diagnosis\" in df.columns, \"The 'diagnosis' column is missing.\"\n",
        "print(\"DataFrame loaded successfully!\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8145d2",
      "metadata": {
        "id": "da8145d2"
      },
      "source": [
        "## 2. Prepare the Data (10 points)\n",
        "\n",
        "Before training a model, the data needs to be preprocessed. This involves encoding the target variable to a numerical format, dropping unnecessary columns, and separating features from the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "034b6a9a",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "42beb4284ddfc5c87be78c6b9f4d9a57",
          "grade": false,
          "grade_id": "w3-q2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "034b6a9a"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 2\n",
        "#\n",
        "# Task: Prepare the data for modeling.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Map the 'diagnosis' column to binary values: 'M' (malignant) to 1 and 'B' (benign) to 0.\n",
        "# 2. Create the feature matrix `X` by dropping the 'diagnosis' column.\n",
        "# 3. Create the target vector `y` from the now-encoded 'diagnosis' column.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df['diagnosis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a425fab5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d9ed080098fbe976c25ad11734fa373c",
          "grade": true,
          "grade_id": "w3-q2-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a425fab5"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 2\n",
        "assert \"X\" in locals() and \"y\" in locals(), \"X and/or y are not defined.\"\n",
        "assert y.dtype == \"int64\" or y.dtype == \"int32\", \"Target 'y' is not numeric.\"\n",
        "assert X.shape[1] == 30, \"Feature matrix 'X' should have 30 columns.\"\n",
        "print(\"Data preparation successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06134391",
      "metadata": {
        "id": "06134391"
      },
      "source": [
        "## 3. Data Splitting and Scaling (10 points)\n",
        "\n",
        "To evaluate the model's performance on unseen data, we must split the dataset into training and testing sets. We will also scale the features, which is crucial for distance-based and optimization-based algorithms like Logistic Regression and LDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e47865",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "417367faf758255f80c49d4fb0a40d1c",
          "grade": false,
          "grade_id": "w3-q3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d2e47865"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 3\n",
        "#\n",
        "# Task: Split and scale the data.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test` with a `test_size` of 0.2 and `random_state=RANDOM_STATE`.\n",
        "# 2. Initialize a `StandardScaler` and fit it on `X_train`.\n",
        "# 3. Transform both `X_train` and `X_test` using the fitted scaler, naming them `X_train_scaled` and `X_test_scaled`.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc3f5bb",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8b7cf2c799cd8951b6767f0e02da815c",
          "grade": true,
          "grade_id": "w3-q3-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dcc3f5bb"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 3\n",
        "assert \"X_train_scaled\" in locals(), \"Scaled training data not found.\"\n",
        "assert \"X_test_scaled\" in locals(), \"Scaled test data not found.\"\n",
        "assert X_train.shape[0] > 0 and X_test.shape[0] > 0, \"Train/test sets are empty.\"\n",
        "print(\"Data splitting and scaling successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f976b940",
      "metadata": {
        "id": "f976b940"
      },
      "source": [
        "## 4. Train a Basic Logistic Regression Model (10 points)\n",
        "\n",
        "Now it's time to train our first classification model. You will use `LogisticRegression` from Scikit-learn to build a baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc4d044",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "898970bf9ed2d60149596c1423ac7803",
          "grade": false,
          "grade_id": "w3-q4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7cc4d044"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 4\n",
        "#\n",
        "# Task: Train a baseline logistic regression model.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Initialize a `LogisticRegression` model, setting `random_state` to `RANDOM_STATE`.\n",
        "# 2. Train the model using the scaled training data (`X_train_scaled`, `y_train`).\n",
        "# 3. Store the trained model in a variable called `log_reg_baseline`.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "log_reg_baseline = LogisticRegression(random_state=RANDOM_STATE)\n",
        "log_reg_baseline.fit(X_train_scaled, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76b1389",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1aeede8f430ac1fb2c00dbfa6ccef93f",
          "grade": true,
          "grade_id": "w3-q4-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a76b1389"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 4\n",
        "assert \"log_reg_baseline\" in locals(), \"Baseline logistic regression model not found.\"\n",
        "assert hasattr(log_reg_baseline, \"coef_\"), \"Model does not appear to be trained.\"\n",
        "print(\"Baseline model training successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa309b7",
      "metadata": {
        "id": "2fa309b7"
      },
      "source": [
        "## 5. Make Predictions and Evaluate (10 points)\n",
        "\n",
        "With a trained model, you can now make predictions and evaluate its performance using key classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04753ec5",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5a38cd6cb9febdd56815ed860e656dbf",
          "grade": false,
          "grade_id": "w3-q5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "04753ec5"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 5\n",
        "#\n",
        "# Task: Make predictions and calculate performance metrics.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Use the baseline model to make predictions on the scaled test data. Store them in `y_pred_baseline`.\n",
        "# 2. Calculate accuracy, precision, recall, and F1-score. Store them in `accuracy_baseline`, `precision_baseline`, `recall_baseline`, and `f1_baseline`.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "y_pred_baseline = log_reg_baseline.predict(X_test_scaled)\n",
        "accuracy_baseline = accuracy_score(y_test, y_pred_baseline, normalize=True)\n",
        "precision_baseline = precision_score(y_test, y_pred_baseline)\n",
        "recall_baseline = recall_score(y_test, y_pred_baseline)\n",
        "f1_baseline = f1_score(y_test, y_pred_baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f1321b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "12dde73adcd2a95f36a50592a9f9e058",
          "grade": true,
          "grade_id": "w3-q5-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "a3f1321b"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 5\n",
        "assert \"y_pred_baseline\" in locals(), \"Baseline predictions not found.\"\n",
        "assert \"accuracy_baseline\" in locals(), \"Baseline accuracy not calculated.\"\n",
        "print(f\"Baseline Accuracy: {accuracy_baseline:.4f}\")\n",
        "print(f\"Baseline Precision: {precision_baseline:.4f}\")\n",
        "print(f\"Baseline Recall: {recall_baseline:.4f}\")\n",
        "print(f\"Baseline F1 Score: {f1_baseline:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d24c97f9",
      "metadata": {
        "id": "d24c97f9"
      },
      "source": [
        "## 6. Compute and Visualize the Confusion Matrix (10 points)\n",
        "\n",
        "The confusion matrix provides a detailed breakdown of correct and incorrect classifications, which is essential for understanding a model's performance beyond a single accuracy score.\n",
        "\n",
        "**Note**: For autograding, only the computed `conf_matrix_baseline` variable will be checked, not the plot itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f2ced5",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8638c61d5a7aa8ca6a40c46f51e3fb16",
          "grade": false,
          "grade_id": "w3-q6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "36f2ced5"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 6\n",
        "#\n",
        "# Task: Compute and visualize the confusion matrix for the baseline model.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Compute the confusion matrix using `y_test` and `y_pred_baseline`. Store it in `conf_matrix_baseline`.\n",
        "# 2. Use `seaborn.heatmap` to visualize the confusion matrix.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "conf_matrix_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
        "sns.heatmap(conf_matrix_baseline, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "565d34e6",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "04e1522692074a7b14ef2b5a6c4ae2dd",
          "grade": true,
          "grade_id": "w3-q6-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "565d34e6"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 6\n",
        "assert \"conf_matrix_baseline\" in locals(), \"Baseline confusion matrix not found.\"\n",
        "assert conf_matrix_baseline.shape == (\n",
        "    2,\n",
        "    2,\n",
        "), \"Confusion matrix has incorrect dimensions.\"\n",
        "print(\"Baseline confusion matrix computed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3d3565",
      "metadata": {
        "id": "1b3d3565"
      },
      "source": [
        "## 7. Plot ROC Curve and Calculate AUC (10 points)\n",
        "\n",
        "The ROC curve illustrates the diagnostic ability of a classifier as its discrimination threshold is varied. The Area Under the Curve (AUC) provides an aggregate measure of performance across all thresholds.\n",
        "\n",
        "**Note**: For autograding, only the computed `roc_auc_baseline` variable will be checked, not the plot itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce404887",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "df7ccf49cf7c4b9a42cd8cb4063b66b1",
          "grade": false,
          "grade_id": "w3-q7",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ce404887"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 7\n",
        "#\n",
        "# Task: Generate the ROC curve for the baseline model.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Get the prediction probabilities for the positive class.\n",
        "# 2. Compute the false positive rate (`fpr`), true positive rate (`tpr`), and thresholds.\n",
        "# 3. Calculate the Area Under the ROC Curve (`roc_auc_baseline`).\n",
        "# 4. Plot the ROC curve.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "y_pred_proba_baseline = log_reg_baseline.predict_proba(X_test_scaled)[:, 1]\n",
        "fpr_baseline, tpr_baseline, thresholds_baseline = roc_curve(y_test, y_pred_proba_baseline)\n",
        "roc_auc_baseline = auc(fpr_baseline, tpr_baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a663d07",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b10b634dc4e1eaa150e9f8e84052a14d",
          "grade": true,
          "grade_id": "w3-q7-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "5a663d07"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 7\n",
        "assert \"roc_auc_baseline\" in locals(), \"ROC AUC for baseline model not calculated.\"\n",
        "assert isinstance(roc_auc_baseline, (float, np.floating)), \"ROC AUC must be a float\"\n",
        "assert 0.0 <= roc_auc_baseline <= 1.0, \"ROC AUC must be between 0 and 1\"\n",
        "assert roc_auc_baseline > 0.5, \"ROC AUC should be better than random (>0.5)\"\n",
        "print(f\"Baseline Model AUC: {roc_auc_baseline:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b796a2",
      "metadata": {
        "id": "11b796a2"
      },
      "source": [
        "## 8. Implement L2 Regularization (10 points)\n",
        "\n",
        "Regularization is a technique to prevent overfitting by penalizing large model coefficients. You will now train a logistic regression model with L2 regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75905ffc",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9bf4e683b3916eac21bc5e6db23ad7e7",
          "grade": false,
          "grade_id": "w3-q8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "75905ffc"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 8\n",
        "#\n",
        "# Task: Train a regularized logistic regression model.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Initialize a `LogisticRegression` model with `penalty='l2'`, `C=0.1`, and `random_state=RANDOM_STATE`.\n",
        "# 2. Train the model on the scaled training data.\n",
        "# 3. Store the trained model in `log_reg_l2`.\n",
        "# 4. Make predictions on the scaled test data and calculate the accuracy, storing it in `accuracy_l2`.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "log_reg_l2 = LogisticRegression(penalty='l2', C=0.1, random_state=RANDOM_STATE)\n",
        "log_reg_l2.fit(X_train_scaled, y_train)\n",
        "y_pred_l2 = log_reg_l2.predict(X_test_scaled)\n",
        "accuracy_l2 = accuracy_score(y_test, y_pred_l2, normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee903775",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0f0f3a2d1d9f8879556ebd462655d8d4",
          "grade": true,
          "grade_id": "w3-q8-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ee903775"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 8\n",
        "assert \"log_reg_l2\" in locals(), \"L2 regularized model not found.\"\n",
        "assert hasattr(log_reg_l2, \"coef_\"), \"L2 model does not appear to be trained.\"\n",
        "assert \"accuracy_l2\" in locals(), \"Accuracy for L2 model not calculated.\"\n",
        "print(f\"L2 Regularized Model Accuracy: {accuracy_l2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7caba860",
      "metadata": {
        "id": "7caba860"
      },
      "source": [
        "## 9. Compare Regularized vs. Unregularized Model (10 points)\n",
        "\n",
        "Let's compare the coefficients of the baseline and regularized models to see the effect of regularization. Regularization should \"shrink\" the coefficients toward zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94597b7c",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "012954bd6896e6a3753f4243b7e574f5",
          "grade": false,
          "grade_id": "w3-q9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "94597b7c"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 9\n",
        "#\n",
        "# Task: Compare the magnitudes of the model coefficients.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Calculate the average absolute value of the coefficients for the baseline model (`log_reg_baseline`) and store it in `avg_coef_baseline`.\n",
        "# 2. Calculate the average absolute value of the coefficients for the L2 regularized model (`log_reg_l2`) and store it in `avg_coef_l2`.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "avg_coef_baseline = np.mean(np.abs(log_reg_baseline.coef_))\n",
        "avg_coef_l2 = np.mean(np.abs(log_reg_l2.coef_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dfc24f1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8031c3cd46a92c8589a6673b0236f2e0",
          "grade": true,
          "grade_id": "w3-q9-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8dfc24f1"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 9\n",
        "assert \"avg_coef_baseline\" in locals(), \"Average baseline coefficient not found.\"\n",
        "assert \"avg_coef_l2\" in locals(), \"Average L2 coefficient not found.\"\n",
        "print(f\"Average Baseline Coefficient Magnitude: {avg_coef_baseline:.4f}\")\n",
        "print(f\"Average L2 Regularized Coefficient Magnitude: {avg_coef_l2:.4f}\")\n",
        "assert (\n",
        "    avg_coef_l2 < avg_coef_baseline\n",
        "), \"L2 coefficients should be smaller than baseline.\"\n",
        "print(\n",
        "    \"Coefficient comparison successful. L2 regularization shrinks coefficients as expected.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6126c4f",
      "metadata": {
        "id": "e6126c4f"
      },
      "source": [
        "## 10. Train a Linear Discriminant Analysis (LDA) Model (10 points)\n",
        "\n",
        "As an alternative approach, let's train a Linear Discriminant Analysis (LDA) model and compare its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7b6369",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ab866a2857ab149142ebca2549fac4ed",
          "grade": false,
          "grade_id": "w3-q10",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fc7b6369"
      },
      "outputs": [],
      "source": [
        "# Grade Cell: Question 10\n",
        "#\n",
        "# Task: Train an LDA model and evaluate its accuracy.\n",
        "#\n",
        "# Instructions:\n",
        "# 1. Initialize a `LinearDiscriminantAnalysis` model.\n",
        "# 2. Train the model on the scaled training data.\n",
        "# 3. Make predictions on the scaled test data.\n",
        "# 4. Calculate the accuracy and store it in `accuracy_lda`.\n",
        "\n",
        "# your code here\n",
        "#raise NotImplementedError\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train_scaled, y_train)\n",
        "y_pred_lda = lda.predict(X_test_scaled)\n",
        "accuracy_lda = accuracy_score(y_test, y_pred_lda, normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11aefcea",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a0d81f3a55b4591418dd1e1b2ec0fe48",
          "grade": true,
          "grade_id": "w3-q10-test",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "11aefcea"
      },
      "outputs": [],
      "source": [
        "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
        "# Test Cell: Question 10\n",
        "assert \"accuracy_lda\" in locals(), \"LDA accuracy not found.\"\n",
        "assert isinstance(accuracy_lda, (float, np.floating)), \"Accuracy must be a float\"\n",
        "assert 0.0 <= accuracy_lda <= 1.0, \"Accuracy must be between 0 and 1\"\n",
        "assert accuracy_lda > 0.5, \"Accuracy should be better than random guessing\"\n",
        "print(f\"LDA Model Accuracy: {accuracy_lda:.4f}\")\n",
        "print(f\"Baseline Logistic Regression Accuracy: {accuracy_baseline:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d04afe5",
      "metadata": {
        "id": "9d04afe5"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Congratulations on completing the assignment! Before submitting:\n",
        "\n",
        "1. Make sure all your cells run without errors.\n",
        "2. Ensure you've answered all parts of each question.\n",
        "3. If any autograder tests fail, revisit your answers.\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "nbgrader,-all",
      "cell_metadata_json": true,
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}