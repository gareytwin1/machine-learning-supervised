{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c9794",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning: Supervised Learning\n",
    "\n",
    "**Instructor:** Daniel Acuna, Ph.D.\n",
    "**Position:** Associate Professor of Computer Science\n",
    "**Institution:** University of Colorado Boulder\n",
    "\n",
    "---\n",
    "\n",
    "Lab 1: Introduction to Machine Learning: Supervised Learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f102ad0",
   "metadata": {},
   "source": [
    "## Setup (do not edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86addce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "RANDOM_STATE: int = 42  # global seed for full reproducibility\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "_DATA_PATH = pathlib.Path(\"california_housing.csv\")\n",
    "if not _DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"california_housing.csv is missing from the lab directory. Please download it or ask the TA \"\n",
    "        \"for assistance.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77edf3",
   "metadata": {},
   "source": [
    "## 1. Load the dataset *(10 points)*\n",
    "\n",
    "Write a function `load_housing()` that reads the CSV into a `pandas.DataFrame`.  Store the shape of\n",
    "that DataFrame in a variable called **`q1_shape`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122b8965",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b04a556ae7b291405776a03e846c650f",
     "grade": false,
     "grade_id": "cal-housing-load",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (20640, 9)\n"
     ]
    }
   ],
   "source": [
    "def load_housing() -> pd.DataFrame:\n",
    "    \"\"\"Load the California Housing data from ``california_housing.csv``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing the 8 predictors plus the target column ``MedHouseVal``.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    # raise NotImplementedError  # Comment this out when implementing\n",
    "    data = pd.read_csv(\"california_housing.csv\")\n",
    "    return data\n",
    "\n",
    "df = load_housing()\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "\n",
    "# Compute the answer required by the autograder\n",
    "q1_shape: Tuple[int, int] = load_housing().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9613b140",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fb1cbddb5254da92ffc625849dedb1a",
     "grade": true,
     "grade_id": "cal-housing-load-test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (20640, 9)\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
    "# Test Cell: Exercise 5.1\n",
    "assert isinstance(q1_shape, tuple), \"q1_shape must be a tuple\"\n",
    "assert len(q1_shape) == 2, \"q1_shape should have 2 elements (rows, cols)\"\n",
    "assert q1_shape[0] > 0 and q1_shape[1] > 0, \"Shape values must be positive\"\n",
    "print(f\"Dataset shape: {q1_shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313dfa5",
   "metadata": {},
   "source": [
    "## 2. Income → Value gap *(10 points)*\n",
    "\n",
    "Split the dataset into **income quartiles** using the ``MedInc`` feature:\n",
    "* bottom 25 % (Q1)\n",
    "* top 25 %  (Q4)\n",
    "\n",
    "Compute the **mean** of the target variable ``MedHouseVal`` for each of those two groups and store\n",
    "their *difference* (**top – bottom**) in **`q2_income_value_gap`** (float, rounded to three\n",
    "decimals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "225ce389",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0baaa40d57b70340711c422cce1654bd",
     "grade": false,
     "grade_id": "income-gap",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 25% mean house value: 1.230\n",
      "Top 25% mean house value: 3.168\n",
      "Income-Value gap: 1.938\n"
     ]
    }
   ],
   "source": [
    "df = load_housing()\n",
    "\n",
    "# your code here\n",
    "# Calculate the 25th and 75th percentiles of MedInc\n",
    "q1_threshold = df['MedInc'].quantile(0.25)  # bottom 25%\n",
    "q4_threshold = df['MedInc'].quantile(0.75)  # top 25%\n",
    "\n",
    "# Filter data into bottom and top quartiles\n",
    "bottom_quartile = df[df['MedInc'] <= q1_threshold]\n",
    "top_quartile = df[df['MedInc'] >= q4_threshold]\n",
    "\n",
    "# Calculate mean MedHouseVal for each group\n",
    "bottom_mean = bottom_quartile['MedHouseVal'].mean()\n",
    "top_mean = top_quartile['MedHouseVal'].mean()\n",
    "\n",
    "# Calculate the difference (top - bottom) and round to 3 decimals\n",
    "q2_income_value_gap = round(top_mean - bottom_mean, 3)\n",
    "\n",
    "print(f\"Bottom 25% mean house value: {bottom_mean:.3f}\")\n",
    "print(f\"Top 25% mean house value: {top_mean:.3f}\")\n",
    "print(f\"Income-Value gap: {q2_income_value_gap:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e2852b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45c238a4fc89b25dd89ceebc05794b02",
     "grade": true,
     "grade_id": "income-gap-test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income-Value gap: 1.938\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
    "# Test Cell: Exercise 5.2\n",
    "assert isinstance(q2_income_value_gap, float), \"q2_income_value_gap must be a float\"\n",
    "assert q2_income_value_gap > 0, \"Gap should be positive (top - bottom)\"\n",
    "assert q2_income_value_gap < 10.0, \"Gap seems unreasonably large\"\n",
    "print(f\"Income-Value gap: {q2_income_value_gap:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16a6cd",
   "metadata": {},
   "source": [
    "## 3. Train/test split *(10 points)*\n",
    "\n",
    "Perform an 80 / 20 split of the predictors ``X`` (all columns except ``MedHouseVal``) and the\n",
    "target ``y`` (only ``MedHouseVal``).  Use ``random_state=RANDOM_STATE``.  Store the **row counts**\n",
    "of each split in a tuple **`q3_split_counts = (n_train, n_test)`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef8e0e4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d570db8d9b75c774f9340a36752fe13b",
     "grade": false,
     "grade_id": "split-counts",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 20640\n",
      "Training set size: 16512\n",
      "Test set size: 4128\n",
      "Train/Test split: 16512 / 4128\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Load the dataset\n",
    "df = load_housing()\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('MedHouseVal', axis=1)  # All columns except MedHouseVal\n",
    "y = df['MedHouseVal']  # Only the target column\n",
    "\n",
    "# Perform 80/20 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Store the row counts as required\n",
    "q3_split_counts = (len(X_train), len(X_test))\n",
    "\n",
    "print(f\"Total dataset size: {len(df)}\") \n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Train/Test split: {q3_split_counts[0]} / {q3_split_counts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7619d58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fe1fc9d5b4c373909c04eb503250a28",
     "grade": true,
     "grade_id": "split-counts-test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test split: 16512 / 4128\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
    "# Test Cell: Exercise 3\n",
    "assert isinstance(q3_split_counts, tuple), \"q3_split_counts must be a tuple\"\n",
    "assert len(q3_split_counts) == 2, \"q3_split_counts should have 2 elements (train, test)\"\n",
    "assert all(\n",
    "    isinstance(n, (int, np.integer)) for n in q3_split_counts\n",
    "), \"Both counts must be integers\"\n",
    "assert all(n > 0 for n in q3_split_counts), \"Both counts must be positive\"\n",
    "print(f\"Train/Test split: {q3_split_counts[0]} / {q3_split_counts[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb330de",
   "metadata": {},
   "source": [
    "## 4. k-NN with *k = 5* *(10 points)*\n",
    "\n",
    "Train a ``KNeighborsRegressor`` with ``n_neighbors=5`` on the training data and compute the **test\n",
    "RMSE**.  Store the scalar in **`q4_knn5_rmse`** rounded to **three** decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9747c969",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "214423bf00215491c28364aefeb73c58",
     "grade": false,
     "grade_id": "knn5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN (k=5) Test RMSE: 1.058\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Create a k-NN regressor with k=5\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model on training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate RMSE (Root Mean Square Error)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Store the result rounded to 3 decimals\n",
    "q4_knn5_rmse = round(rmse, 3)\n",
    "\n",
    "print(f\"k-NN (k=5) Test RMSE: {q4_knn5_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55777bc5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a29c820b54da0c08510267eca2e4056",
     "grade": true,
     "grade_id": "knn5-test",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 10 points\n",
    "# Test Cell: Exercise 5.4\n",
    "assert isinstance(q4_knn5_rmse, float), \"RMSE must be a float\"\n",
    "assert q4_knn5_rmse >= 0, \"RMSE must be non-negative\"\n",
    "assert q4_knn5_rmse < 10.0, \"RMSE seems unreasonably large\"\n",
    "print(f\"k-NN (k=5) Test RMSE: {q4_knn5_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282d97f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 5. Reusable k-NN evaluator *(15 points)*\n",
    "\n",
    "Implement a function **`knn_rmse(k: int) -> float`** that\n",
    "1. trains a ``KNeighborsRegressor`` with the given *k* on **`X_train`, `y_train`** (from Exercise 5.3),\n",
    "2. returns the **test RMSE** rounded to three decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32a1341",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a67865ffb56fac9a79dd5acd563f6dee",
     "grade": false,
     "grade_id": "knn-func",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_rmse(5) = 1.058\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def knn_rmse(k: int) -> float:\n",
    "    \"\"\"Train a k-NN regressor and return test RMSE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        Number of neighbors for the KNeighborsRegressor\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Test RMSE rounded to 3 decimals\n",
    "    \"\"\"\n",
    "    # Create k-NN regressor with the given k\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    \n",
    "    # Train on training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Return rounded to 3 decimals\n",
    "    return round(rmse, 3)\n",
    "\n",
    "# Test the function\n",
    "print(f\"knn_rmse(5) = {knn_rmse(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcb1930d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96f43f599b13e4830728def403da09b2",
     "grade": true,
     "grade_id": "knn-func-test",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_rmse(5) = 1.058\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 15 points\n",
    "# Test Cell: Exercise 5.5\n",
    "assert callable(knn_rmse), \"knn_rmse should be a callable function\"\n",
    "# Test with k=5\n",
    "test_rmse = knn_rmse(5)\n",
    "assert isinstance(test_rmse, float), \"knn_rmse should return a float\"\n",
    "assert test_rmse >= 0, \"RMSE must be non-negative\"\n",
    "assert test_rmse < 10.0, \"RMSE seems unreasonably large\"\n",
    "print(f\"knn_rmse(5) = {test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2295514",
   "metadata": {},
   "source": [
    "## 6. Linear Regression baseline *(15 points)*\n",
    "\n",
    "Fit an ordinary least-squares ``LinearRegression`` model (with default settings) on the training\n",
    "data and compute its **test RMSE**.  Store the value in **`q6_linreg_rmse`** rounded to three\n",
    "decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef7cd9f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4851e374cbd73d0e05c67cbe9722e0f",
     "grade": false,
     "grade_id": "linreg",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test RMSE: 0.746\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Create a Linear Regression model with default settings\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model on training data\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# Calculate RMSE (Root Mean Square Error)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Store the result rounded to 3 decimals\n",
    "q6_linreg_rmse = round(rmse, 3)\n",
    "\n",
    "print(f\"Linear Regression Test RMSE: {q6_linreg_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc026063",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5231cca20ae5ef1f44d2742263899e9",
     "grade": true,
     "grade_id": "linreg-test",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test RMSE: 0.746\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 15 points\n",
    "# Test Cell: Exercise 6\n",
    "assert isinstance(q6_linreg_rmse, float), \"RMSE must be a float\"\n",
    "assert q6_linreg_rmse >= 0, \"RMSE must be non-negative\"\n",
    "assert q6_linreg_rmse < 10.0, \"RMSE seems unreasonably large\"\n",
    "print(f\"Linear Regression Test RMSE: {q6_linreg_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe21fd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 7. 5-fold CV for multiple *k* values *(15 points)*\n",
    "\n",
    "Implement **`cross_val_knn(k_values: List[int]) -> Dict[int, float]`** that performs\n",
    "5-fold cross-validation *only on the training split* for each *k* in `k_values` and returns a\n",
    "dictionary mapping *k* → mean CV RMSE (rounded to three decimals).  Use\n",
    "``KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddda0335",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24389ae7143db8b13b2ce2d179398d74",
     "grade": false,
     "grade_id": "cv-knn",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cross-validation results: {3: 1.108, 5: 1.081}\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def cross_val_knn(k_values: List[int]) -> Dict[int, float]:\n",
    "    \"\"\"Perform 5-fold cross-validation for k-NN with multiple k values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k_values : List[int]\n",
    "        List of k values to evaluate\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[int, float]\n",
    "        Dictionary mapping k -> mean CV RMSE (rounded to 3 decimals)\n",
    "    \"\"\"\n",
    "    # Create KFold splitter as specified\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Create k-NN regressor with current k\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        \n",
    "        # Perform cross-validation on training data only\n",
    "        # Use negative mean squared error scoring\n",
    "        cv_scores = cross_val_score(knn, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        \n",
    "        # Convert negative MSE to RMSE and take mean\n",
    "        rmse_scores = np.sqrt(-cv_scores)  # Convert neg MSE to positive RMSE\n",
    "        mean_rmse = np.mean(rmse_scores)\n",
    "        \n",
    "        # Store result rounded to 3 decimals\n",
    "        results[k] = round(mean_rmse, 3)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the function with a couple of k values\n",
    "test_result = cross_val_knn([3, 5])\n",
    "print(f\"Sample cross-validation results: {test_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59f6d6f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fdf16b7915a8a701c6f73d53eab6923",
     "grade": true,
     "grade_id": "cv-knn-test",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample CV scores: {3: 1.108, 5: 1.081}\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 15 points\n",
    "# Test Cell: Exercise 7\n",
    "test_vals = cross_val_knn([3, 5])\n",
    "assert callable(cross_val_knn), \"cross_val_knn should be a callable function\"\n",
    "assert isinstance(test_vals, dict), \"cross_val_knn should return a dictionary\"\n",
    "assert len(test_vals) == 2, \"Dictionary should have one entry per k value\"\n",
    "assert all(isinstance(k, int) for k in test_vals.keys()), \"Keys should be integers\"\n",
    "assert all(isinstance(v, float) for v in test_vals.values()), \"Values should be floats\"\n",
    "assert all(v >= 0 for v in test_vals.values()), \"RMSE values must be non-negative\"\n",
    "print(f\"Sample CV scores: {test_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa004e9e",
   "metadata": {},
   "source": [
    "## 8. Choose best *k* and evaluate on test set *(15 points)*\n",
    "\n",
    "1. Use your `cross_val_knn` from Exercise 5.7 with the list `[1, 3, 5, 7, 9, 15, 25]`.\n",
    "2. Identify the *k* that achieves the **lowest** cross-validated RMSE → **`q8_best_k`\n",
    "3. Finally, use your `knn_rmse` function from Exercise 5.5 to compute the **test set RMSE** for this best *k* → **`q8_test_rmse`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a865d74",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "350495aea2c861352137551476fb0e62",
     "grade": false,
     "grade_id": "best-k",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "k=1: CV RMSE = 1.286\n",
      "k=3: CV RMSE = 1.108\n",
      "k=5: CV RMSE = 1.081\n",
      "k=7: CV RMSE = 1.075\n",
      "k=9: CV RMSE = 1.073\n",
      "k=15: CV RMSE = 1.082\n",
      "k=25: CV RMSE = 1.098\n",
      "\n",
      "Best k (lowest CV RMSE): 9\n",
      "Best CV RMSE: 1.073\n",
      "\n",
      "Final test set RMSE for k=9: 1.050\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "Best k: 9\n",
      "Test RMSE: 1.050\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Define the k candidates to evaluate\n",
    "k_candidates = [1, 3, 5, 7, 9, 15, 25]\n",
    "\n",
    "# Step 1: Use cross_val_knn to get CV RMSE for each k\n",
    "cv_results = cross_val_knn(k_candidates)\n",
    "print(\"Cross-validation results:\")\n",
    "for k, rmse in cv_results.items():\n",
    "    print(f\"k={k}: CV RMSE = {rmse:.3f}\")\n",
    "\n",
    "# Step 2: Find the k with the lowest CV RMSE\n",
    "q8_best_k = min(cv_results, key=cv_results.get)\n",
    "print(f\"\\nBest k (lowest CV RMSE): {q8_best_k}\")\n",
    "print(f\"Best CV RMSE: {cv_results[q8_best_k]:.3f}\")\n",
    "\n",
    "# Step 3: Use knn_rmse to get test set performance for the best k\n",
    "q8_test_rmse = knn_rmse(q8_best_k)\n",
    "print(f\"\\nFinal test set RMSE for k={q8_best_k}: {q8_test_rmse:.3f}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Best k: {q8_best_k}\")\n",
    "print(f\"Test RMSE: {q8_test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a70ec88",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d40b802433ed6d2bf8272c7469a40232",
     "grade": true,
     "grade_id": "best-k-test",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 9, Test RMSE: 1.050\n"
     ]
    }
   ],
   "source": [
    "# If all tests pass (there might be hidden tests), you will earn 15 points\n",
    "# Test Cell: Exercise 8\n",
    "k_candidates = [1, 3, 5, 7, 9, 15, 25]\n",
    "assert isinstance(q8_best_k, int), \"q8_best_k must be an integer\"\n",
    "assert q8_best_k > 0, \"k must be positive\"\n",
    "assert isinstance(q8_test_rmse, float), \"q8_test_rmse must be a float\"\n",
    "assert q8_test_rmse >= 0, \"RMSE must be non-negative\"\n",
    "assert q8_test_rmse < 10.0, \"RMSE seems unreasonably large\"\n",
    "print(f\"Best k: {q8_best_k}, Test RMSE: {q8_test_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc0330",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations on completing the assignment! Before submitting:\n",
    "\n",
    "1. Make sure all your cells run without errors.\n",
    "2. Ensure you've answered all parts of each question.\n",
    "3. If any autograder tests fail, revisit your answers.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
